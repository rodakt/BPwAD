{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biblioteki Pythona w analizie danych\n",
    "### Tomasz Rodak\n",
    "\n",
    "Lab 10\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Transfer learning\n",
    "\n",
    "Celem tego laboratorium jest zapoznanie się z metodą [*transfer learningu*](https://en.wikipedia.org/wiki/Transfer_learning) (uczenia transferowego). Transfer learning to technika uczenia maszynowego, która polega na przenoszeniu wiedzy zdobytej podczas rozwiązywania jednego problemu do innego, pokrewnego problemu. W praktyce oznacza to, że zamiast trenować model od podstaw na dużym zbiorze danych, możemy wykorzystać model, który został już wytrenowany na innym zbiorze danych i dostosować go do naszych potrzeb. Jest to szczególnie przydatne w sytuacjach, gdy mamy ograniczone zasoby obliczeniowe lub mało danych do trenowania. \n",
    "\n",
    "Transfer learning zademonstrujemy na przykładzie problemu rozpoznawania obrazów. Wykorzystamy do tego celu pretrenowany model [ResNet18](https://arxiv.org/pdf/1512.03385). Obrazy do klasyfikacji pobierzemy z sekcji *Images* wyszukiwarki [DuckDuckGo](https://duckduckgo.com/). Wykorzystamy PyTorch do budowy i trenowania modelu.\n",
    "\n",
    "Arkusz ten powstał na podstawie kursu [fastai](https://course.fast.ai/), Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Instalacje i importy\n",
    "\n",
    "Brakuje nam pakietu [`duckduckgo-search`](https://github.com/deedy5/duckduckgo_search). Pakiet ten wykorzystamy do utworzenia listy odnośników do obrazów, zainstalujesz go poleceniem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import hashlib\n",
    "import os\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "import requests\n",
    "import tqdm.notebook as tqdm\n",
    "from duckduckgo_search import DDGS\n",
    "from PIL import Image, UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Pobieranie obrazów\n",
    "\n",
    "Dla uproszczenia załóżmy, że chcemy rozpoznać dwa rodzaje obrazów, później możesz to oczywiście zmienić. Zaproponuj jakieś dwie kategorie. Dane będziemy pobierać z wyszukiwarki DuckDuckGo z sekcji *Images* wyszukiwania, więc uwzględnij wynikające stąd ograniczenia. Wybór bardzo specyficznej kategorii o słabej reprezentacji w internecie może skutkować nieadekwatnym zbiorem danych. Wybierz takie kategorie, o których spodziewasz się, że będą miały dobrą reprezentację w internecie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.1 Funkcje pomocnicze\n",
    "\n",
    "Funkcje `to_hash()` i `seen_files()` są pomocnicze. Funkcja `to_hash()` konwertuje ciąg znaków na hash MD5, a funkcja `seen_files()` pobiera zbiór nazw plików (bez rozszerzeń) z folderu. Użyjemy ich do sprawdzenia, czy dany obraz został już pobrany. Takie śledzenie plików jest istotne, gdyż różne zapytania do wyszukiwarki mogą czasami zwracać te same obrazy - nie chcemy ich pobierać więcej niż raz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_hash(s):\n",
    "    \"\"\"\n",
    "    Konwertuje ciąg znaków na hash MD5.\n",
    "    \n",
    "    Argumenty:\n",
    "        s (str): Ciąg znaków do hashowania\n",
    "        \n",
    "    Zwraca:\n",
    "        str: Hash MD5 podanego ciągu w formacie szesnastkowym\n",
    "    \"\"\"\n",
    "    return hashlib.md5(s.encode()).hexdigest()\n",
    "\n",
    "def seen_files(folder):\n",
    "    \"\"\"\n",
    "    Pobiera zbiór nazw plików (bez rozszerzeń) z folderu.\n",
    "    \n",
    "    Argumenty:\n",
    "        folder (str lub Path): Ścieżka do folderu do przeskanowania\n",
    "        \n",
    "    Zwraca:\n",
    "        set: Zbiór nazw plików bez rozszerzeń\n",
    "    \"\"\"\n",
    "    files = os.listdir(folder)\n",
    "    return set(Path(file).stem for file in files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.2 Foldery\n",
    "\n",
    "Tworzę folder `datasets/imgrec`, w którym będą przechowywane pobrane obrazy. Będę rozpoznawał obrazy dzika i jelenia. Aby je przechować, tworzę podfoldery `boar` i `deer`. Powinieneś wybrać inne kategorie, ale foldery powinny mieć podobną strukturę. Oznacza to, że powinieneś również dokonać odpowiednich zmian w kodzie poniżej, tak aby odpowiadał Twoim kategoriom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p datasets/imgrec\n",
    "!mkdir -p datasets/imgrec/boar\n",
    "!mkdir -p datasets/imgrec/deer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.3 Zapytanie do wyszukiwarki\n",
    "\n",
    "W tym miejscu tworzymy zapytanie do wyszukiwarki. **Upewnij się, że zapytanie jest odpowiednie do kategorii!** (zmienne `keywords` i `category`). Zbiór danych zostałby uszkodzony, gdybym przykładowo w kategorii `boar` dodał zapytanie o `deer`. W takim przypadku nie da się poprawnie wytrenować modelu.\n",
    "\n",
    "Zapytanie delegowane jest do wyszukiwarki DuckDuckGo, która zwraca listę linków do obrazów (`images_links`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "keywords = 'dzik pospolity'\n",
    "category = 'boar'\n",
    "\n",
    "with DDGS() as ddgs:\n",
    "    images_gen = ddgs.images(\n",
    "        keywords,\n",
    "        max_results=100\n",
    "    )\n",
    "    images_links = list(images_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.4 Pobieranie obrazów\n",
    "\n",
    "Główna pętla pobierająca obrazy iteruje po wszystkich linkach i pobiera je asynchronicznie. Używamy `asyncio` do równoległego pobierania obrazów, co przyspiesza cały proces. Ważne zmienne:\n",
    "- `FOLDER` - folder, w którym znajduje się zbiór danych\n",
    "- `subfolder` - podfolder, w którym będą przechowywane pobrane obrazy w danej kategorii\n",
    "- `already_seen` - zbiór nazw plików, które zostały już pobrane.\n",
    "\n",
    "Nazwy plików są generowane na podstawie hasha MD5 adresu URL obrazu. Dzięki temu unikamy niespodziewanych znaków w nazwach plików. Funkcja `download_image_async()` sprawdza liczne możliwe błędy:\n",
    "- `httpx.HTTPError` - błąd HTTP\n",
    "- `httpx.TimeoutException` - przekroczony czas oczekiwania na odpowiedź\n",
    "- `UnidentifiedImageError` - błąd związany z otwieraniem obrazu, dzięki czemu zapisujemy tylko poprawne obrazy.\n",
    "\n",
    "Program ten możesz wykonywać wielokrotnie, pamiętaj jednak, aby wcześniej wstawić odpowiednie zapytanie i kategorię w komórce powyżej. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = Path('datasets/imgrec')\n",
    "subfolder = FOLDER/category\n",
    "already_seen = seen_files(subfolder)\n",
    "print(f'Now {len(already_seen)} files in {subfolder}')\n",
    "counter = 0\n",
    "\n",
    "async def download_image_async(client, image_url, already_seen, subfolder, to_hash, semaphore):\n",
    "    async with semaphore:  # Limit concurrent downloads\n",
    "        file = to_hash(image_url)\n",
    "\n",
    "        if file in already_seen:\n",
    "            print(f'Already seen: {file}={image_url}')\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:120.0) Gecko/20100101 Firefox/120.0'\n",
    "            }\n",
    "            r = await client.get(image_url, headers=headers, timeout=5)\n",
    "        except httpx.HTTPError as e:\n",
    "            print(f'HTTPError: {e} for {image_url}')\n",
    "            return None\n",
    "        except httpx.TimeoutException:\n",
    "            print(f'Timeout: {image_url}')\n",
    "            return None\n",
    "        except httpx.SSLError:\n",
    "            print(f'SSLError: {image_url}')\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            img = Image.open(BytesIO(r.content))\n",
    "        except UnidentifiedImageError:\n",
    "            print(f'Image error for {image_url}')\n",
    "            return None\n",
    "\n",
    "        file = Path(file).with_suffix(f'.{img.format.lower()}')\n",
    "        print(f'New file = {image_url}')\n",
    "\n",
    "        with open(subfolder/file, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "            print(f'Saved {file} to {subfolder}')\n",
    "\n",
    "        return file\n",
    "\n",
    "max_concurrent = 10  \n",
    "semaphore = asyncio.Semaphore(max_concurrent)\n",
    "\n",
    "client = httpx.AsyncClient(limits=httpx.Limits(max_connections=20))\n",
    "\n",
    "tasks = []\n",
    "for image in images_links:\n",
    "    image_url = image['image']\n",
    "    task = download_image_async(client, image_url, already_seen, subfolder, to_hash, semaphore)\n",
    "    tasks.append(task)\n",
    "\n",
    "results = await asyncio.gather(*tasks)\n",
    "await client.aclose()  # Close the client when done\n",
    "\n",
    "successful = [r for r in results if r is not None]\n",
    "print(f'Total files downloaded: {len(successful)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.5 Rozmiar zebranych danych\n",
    "\n",
    "Rozmiar folderu `datasets/imgrec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hsc datasets/imgrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba pobranych obrazów w folderze `boar`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh datasets/imgrec/boar/|wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba pobranych obrazów w folderze `deer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh datasets/imgrec/deer/|wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Klasyfikacja\n",
    "#### 10.3.1 Przygotowanie danych treningowych\n",
    "\n",
    "Wykorzystamy zbiór danych, który pobraliśmy w poprzednim kroku. Musimy przygotować go do treningu naszego modelu, co obejmuje:\n",
    "1. Załadowanie obrazów z dysków \n",
    "2. Podzielenie na zbiór treningowy, walidacyjny i testowy\n",
    "3. Przekształcenie ich do odpowiedniego formatu, zastosowanie augmentacji i normalizacji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załaduj zbiór danych z dysku. Wykorzystaj `torchvision.datasets.ImageFolder` z parametrem `transform=None`.\n",
    "Zobacz, jakiego rodzaju obiekt otrzymałeś. Podejrzyj jego atrybuty. Wyświetl przykładowe obrazki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podziel zbiór na treningowy, walidacyjny i testowy. Użyj `torch.utils.data.random_split()`. Ustaw generator, aby zapewnić powtarzalność podziału: `generator=torch.Generator().manual_seed(<seed>)`. W wyniku tej operacji otrzymasz trzy zbiory danych typu `torch.utils.data.dataset.Subset` - są to **widoki** na fragmenty oryginalnego zbioru danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oblicz proporcje klas w zbiorze treningowym, walidacyjnym i testowym. Możesz użyć np. `collections.Counter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniuj transformacje:\n",
    "- dla zbioru treningowego:\n",
    "  - losowa zmiana rozmiaru i przycięcie do 224x224\n",
    "  - losowe odbicie lustrzane\n",
    "  - konwersja do tensora\n",
    "  - normalizacja (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "- dla zbioru walidacyjnego i testowego:\n",
    "  - zmiana rozmiaru do 256\n",
    "  - przycięcie do 224x224\n",
    "  - konwersja do tensora\n",
    "  - normalizacja (`mean=[0.485, 0.456, 0.406]`, `std=[0.229, 0.224, 0.225]`, dane z ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do obrazów chcemy stosować różne transformacje – osobne dla zbioru treningowego, walidacyjnego i testowego. W instancjach klas dziedziczących po `torch.utils.data.Dataset` (np. `ImageFolder`) transformacje, jeśli zostały przekazane jako argument `transform`, są wywoływane automatycznie w metodzie `__getitem__()`.\n",
    "\n",
    "Ponieważ chcemy zachować jeden wspólny zestaw danych (np. z `ImageFolder`), a podziały na train/val/test mają korzystać z różnych transformacji, stworzymy własny wrapper. Napisz klasę `TransformedSubset`, dziedziczącą po `torch.utils.data.Dataset`, która:\n",
    "1. W konstruktorze przyjmuje:\n",
    "   * dowolny obiekt `torch.utils.data.Dataset` lub `Subset` (np. wynik `random_split`),\n",
    "   * obiekt transformacji (`torchvision.transforms.Compose` albo inny).\n",
    "2. Nadpisuje metodę `__getitem__(self, idx)`, aby:\n",
    "   * pobrać surowy przykład przez `self.subset[idx]`,\n",
    "   * nałożyć przekazaną transformację na obraz,\n",
    "   * zwrócić `(image_transformed, label)`.\n",
    "3. Nadpisuje metodę `__len__(self)`, delegując wywołanie do wewnętrznego podzbioru (`len(self.subset)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosuj `TransformedSubset` do każdego podzbioru. Użyj `torch.utils.data.DataLoader`, aby utworzyć iteratory dla każdego zbioru danych. Ustaw odpowiedni rozmiar wsadu i `shuffle=True` dla zbioru treningowego oraz `shuffle=False` dla pozostałych zbiorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2 Model\n",
    "\n",
    "Pobierz (pretrenowany) model ResNet18 z repozytorium torchvision. Ustaw go w tryb ewaluacji. Sprawdź, czy GPU jest dostępne. Jeśli tak, przenieś tam model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2 Modyfikacja modelu\n",
    "\n",
    "Modyfikujemy model ResNet18, aby dostosować go do naszego zadania klasyfikacji: ostatnią warstwę, zmieniamy tak aby miała 2 wyjścia (boar i deer) zamiast 1000 (jak w oryginalnym modelu trenowanym na ImageNet). Jedynie ta warstwa będzie trenowana, pozostałe będą zamrożone. \n",
    "\n",
    "Ustaw `requires_grad=False` dla wszystkich parametrów modelu. Skutek tego działania jest taki, że podczas trenowania modelu nie będą one aktualizowane. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zidentyfikuj ostatnią warstwę modelu i podmień ją na `nn.Linear(<in_features>, 2)`, gdzie `<in_features>` to liczba cech wejściowych tej warstwy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3 Trenowanie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ustaw funkcję straty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ustaw optymalizator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeprowadź trening modelu. W miarę możliwości śledź postęp treningu. Ile epok należy przeprowadzić? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.4 Ocena\n",
    "\n",
    "- Oblicz dokładność i wyświetl macierz pomyłek dla zbioru testowego.\n",
    "- Pokaż przykłady błędnie sklasyfikowanych obrazów.\n",
    "- Wykonaj klasyfikacje dla nowych obrazów pobranych z internetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
