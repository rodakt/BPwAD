{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biblioteki Pythona w analizie danych\n",
    "\n",
    "## Tomasz Rodak\n",
    "\n",
    "Wykład 6\n",
    "\n",
    "---\n",
    "\n",
    "Literatura:\n",
    "\n",
    "- [PRML](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) Christopher M. Bishop, \"Pattern Recognition and Machine Learning\", 2006.\n",
    "- [PML-1](https://probml.github.io/pml-book/) Kevin P. Murphy, \"Probabilistic Machine Learning: An Introduction\", 2022.\n",
    "- C.M. Bishop, [Deep Learning, Foundations and Concepts](https://www.bishopbook.com/)\n",
    "- [Dokumentacja NumPy](https://numpy.org/doc/stable/)\n",
    "- [Dokumentacja scikit-learn](https://scikit-learn.org/stable/)\n",
    "- [Dokumentacja PyTorch](https://pytorch.org/docs/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metoda gradientu prostego. Tensory i różniczkowanie automatyczne w PyTorch\n",
    "\n",
    "## Optymalizacja metodą gradientu prostego\n",
    "\n",
    "Załóżmy, że $L(\\mathbf{w})$ jest funkcją straty dla modelu z parametrami $\\mathbf{w}$. Funkcja $L$ zwraca nieujemną wartość reprezentującą stopień w jakim przewidywania modelu różnią się od rzeczywistych wartości. Typowe przykłady to:\n",
    "\n",
    "**Błąd średniokwadratowy** (MSE) dla problemów regresji:\n",
    "  \n",
    "  \\begin{equation*}\n",
    "    L(\\mathbf{w}) = \\frac{1}{N} \\sum_{i=1}^N (y_i - f(\\mathbf{x}_i, \\mathbf{w}))^2\n",
    "  \\end{equation*}\n",
    "\n",
    "gdzie $y_i$ to rzeczywista wartość, a $f(\\mathbf{x}_i, \\mathbf{w})$ to przewidywana wartość przez model dla danych wejściowych $\\mathbf{x}_i$.\n",
    "\n",
    "**Entropia krzyżowa** (*cross-entropy*) dla problemów klasyfikacji binarnej:\n",
    "\n",
    "  \\begin{equation*}\n",
    "    L(\\mathbf{w}) = -\\frac{1}{N} \\sum_{i=1}^N \\left( y_i \\log(f(\\mathbf{x}_i, \\mathbf{w})) + (1 - y_i) \\log(1 - f(\\mathbf{x}_i, \\mathbf{w})) \\right)\n",
    "  \\end{equation*}\n",
    "\n",
    "gdzie $y_i$ to etykieta klasy (0 lub 1), a $f(\\mathbf{x}_i, \\mathbf{w})$ to przewidywana prawdopodobieństwo przynależności do klasy 1.\n",
    "\n",
    "**Entropia krzyżowa** (*cross-entropy*) dla problemów klasyfikacji wieloklasowej:\n",
    "\n",
    "  \\begin{equation*}\n",
    "    L(\\mathbf{w}) = -\\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^K y_{ij} \\log(f_j(\\mathbf{x}_i, \\mathbf{w}))\n",
    "  \\end{equation*}\n",
    "\n",
    "gdzie $y_{ij}$ to etykieta klasy (1 jeśli próbka $i$ należy do klasy $j$, 0 w przeciwnym razie), a $f_j(\\mathbf{x}_i, \\mathbf{w})$ to przewidywana prawdopodobieństwo przynależności do klasy $j$.\n",
    "\n",
    "Trening modelu polega na minimalizacji funkcji straty $L(\\mathbf{w})$ względem parametrów $\\mathbf{w}$. Metoda wykorzystywana do znalezienia minimum lokalnego funkcji $L(\\mathbf{w})$ zależy przede wszystkim od tego, czy funkcja $L$ jest różniczkowalna względem $\\mathbf{w}$, czy też nie:\n",
    "- **Jeśli $L(\\mathbf{w})$ jest różniczkowalna**, to zwykle korzysta się z jakiegoś wariantu metody gradientu prostego (o czym opowiemy za chwilę).\n",
    "- **Jeśli $L(\\mathbf{w})$ nie jest różniczkowalna**, lub informacja o gradientach nie jest dostępna, to stosuje się metody takie jak algorytmy ewolucyjne, optymalizację bayesowską, symulowane wyżarzanie, i wiele innych. \n",
    "\n",
    "Optymalizacja metodą gradientu prostego jest algorytmem iteracyjnym. Polega on na tym, że w pierwszym kroku wybieramy jakąś wartość początkową dla parametrów $\\mathbf{w}^{(0)}$ (np. losowo), a następnie w każdym kroku $\\tau$ aktualizujemy parametry $\\mathbf{w}^{(\\tau)}$ zgodnie z równaniem:\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\mathbf{w}^{(\\tau)} = \\mathbf{w}^{(\\tau - 1)} + \\left(\\text{krok zależny od }\\mathbf{w}^{(\\tau - 1)}\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "Wybór kroku zależnego od $\\mathbf{w}^{(\\tau - 1)}$ jest kluczowy dla działania algorytmu i właśnie w tym miejscu wykorzystuje się informację o gradiencie funkcji $L(\\mathbf{w})$ w punkcie $\\mathbf{w}^{(\\tau - 1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Batch gradient descent*\n",
    "\n",
    "Termin *batch* oznacza, że funkcję straty $L(\\mathbf{w})$ będziemy obliczali na podstawie całego zbioru danych. Matematycznie *batch gradient descent* definiuje ciąg $\\mathbf{w}^{(\\tau)}$ wzorem indukcyjnym:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "  \\mathbf{w}^{(0)} &= \\text{losowo ustalona początkowa wartość parametrów modelu} \\\\\n",
    "  \\mathbf{w}^{(\\tau)} &= \\mathbf{w}^{(\\tau - 1)} - \\eta \\nabla_{\\mathbf{w}} L(\\mathbf{w}^{(\\tau - 1)}),\\quad \\tau = 1, 2, \\ldots\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie **współczynnik uczenia** (*learning rate*) $\\eta>0$ jest hiperparametrem algorytmu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Batch gradient descent* w pseudokodzie:\n",
    "\n",
    "> **Input**: \n",
    ">   * zbiór danych $\\mathcal{D} = \\{(\\mathbf{x}_n, y_n)\\}_{n=1}^N$,\n",
    ">   * funkcja straty $L(\\mathbf{w})$ obliczana na podstawie całego zbioru danych $\\mathcal{D}$\n",
    ">   * współczynnik uczenia $\\eta>0$,\n",
    ">   * losowo inicjalizowana początkowa wartość parametrów modelu $\\mathbf{w}$.\n",
    "> \n",
    "> **Output**: \n",
    ">   * parametry modelu $\\mathbf{w}$ po zakończeniu treningu.\n",
    ">\n",
    "> **Algorytm**:\n",
    ">\n",
    "> 1. Powtarzaj:\n",
    ">    * $\\mathbf{w} \\gets \\mathbf{w} - \\eta \\nabla_{\\mathbf{w}} L(\\mathbf{w})$.\n",
    "> 2. aż do osiągnięcia zbieżności.\n",
    "> 3. Zwróć $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Stochastic gradient descent* (SGD)\n",
    "\n",
    "Funkcja straty $L(\\mathbf{w})$ często daje się zapisać jako suma strat dla poszczególnych próbek:\n",
    "\n",
    "\\begin{equation*}\n",
    "  L(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^N L_n(\\mathbf{w}),\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $L_n(\\mathbf{w})$ to strata dla próbki $n$. Przykładowo, dla problemu regresji z funkcją straty MSE mamy:\n",
    "\n",
    "\\begin{equation*}\n",
    "  L(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^N (y_n - f(\\mathbf{x}_n, \\mathbf{w}))^2 = \\frac{1}{N} \\sum_{n=1}^N L_n(\\mathbf{w}),\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $L_n(\\mathbf{w}) = (y_n - f(\\mathbf{x}_n, \\mathbf{w}))^2$. Podobnie dla entropii krzyżowej mamy:\n",
    "\n",
    "\\begin{equation*}\n",
    "  L(\\mathbf{w}) = -\\frac{1}{N} \\sum_{n=1}^N\\sum_{j=1}^K y_{nj} \\log(f_j(\\mathbf{x}_n, \\mathbf{w})) = \\frac{1}{N} \\sum_{n=1}^N L_n(\\mathbf{w}),\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $L_n(\\mathbf{w}) = -\\sum_{j=1}^K y_{nj} \\log(f_j(\\mathbf{x}_n, \\mathbf{w}))$. \n",
    "\n",
    "Jeśli $L(\\mathbf{w})$ można zapisać jak wyżej, to gradient $\\nabla_{\\mathbf{w}} L(\\mathbf{w})$ jest równy średniej z gradientów $L_n(\\mathbf{w})$:\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\nabla_{\\mathbf{w}} L(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^N \\nabla_{\\mathbf{w}} L_n(\\mathbf{w}).\n",
    "\\end{equation*}\n",
    "\n",
    "Obserwacja ta jest wykorzystywana w algorytmie *stochastic gradient descent* (SGD), który polega na tym, że w każdym kroku aktualizujemy parametry $\\mathbf{w}^{(\\tau)}$ wykorzystując gradient tylko dla jednej próbki $n$ zamiast dla całego zbioru jak w przypadku *batch gradient descent*. Matematycznie SGD definiuje ciąg $\\mathbf{w}^{(\\tau)}$ wzorem indukcyjnym:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "  \\mathbf{w}^{(0)} &= \\text{losowo ustalona początkowa wartość parametrów modelu} \\\\\n",
    "  \\mathbf{w}^{(\\tau)} &= \\mathbf{w}^{(\\tau - 1)} - \\eta \\nabla_{\\mathbf{w}} L_n(\\mathbf{w}^{(\\tau - 1)}),\\quad \\tau = 1, 2, \\ldots\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "gdzie $n$ jest numerem próbki zależnym od kroku $\\tau$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD w pseudokodzie:\n",
    "\n",
    "> **Input**:\n",
    ">   * zbiór danych $\\mathcal{D} = \\{(\\mathbf{x}_n, y_n)\\}_{n=1}^N$,\n",
    ">   * funkcja straty $L_n(\\mathbf{w})$ obliczana na podstawie próbki $n$,\n",
    ">   * współczynnik uczenia $\\eta>0$,\n",
    ">   * losowo inicjalizowana początkowa wartość parametrów modelu $\\mathbf{w}$.\n",
    ">\n",
    "> **Output**:\n",
    ">   * parametry modelu $\\mathbf{w}$ po zakończeniu treningu.\n",
    ">\n",
    "> **Algorytm**:\n",
    ">\n",
    "> 1. $n \\gets 1$.\n",
    "> 2. Powtarzaj:\n",
    ">    * $\\mathbf{w} \\gets \\mathbf{w} - \\eta \\nabla_{\\mathbf{w}} L_n(\\mathbf{w})$\n",
    ">    * $n \\gets n + 1$\n",
    ">    * jeśli $n > N$, to:\n",
    ">      * wymieszaj dane $\\mathcal{D}$,\n",
    ">      * $n \\gets 1$.\n",
    "> 3. aż do osiągnięcia zbieżności.\n",
    "> 4. Zwróć $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorytm ten w ciągu $N$ kroków pętli wykona $N$ aktualizacji parametrów $\\mathbf{w}$ przepuszczając przez model wszystkie próbki. Korzysta się z następującej terminologii:\n",
    "* **iteracja** (*iteration*) - pojedyncza aktualizacja parametrów $\\mathbf{w}$, czyli przetworzenie jednej próbki,\n",
    "* **epoka** (*epoch*) - pełne przejście przez cały zbiór danych, czyli $N$ iteracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Mini-batch gradient descent*\n",
    "\n",
    "*Mini-batch gradient descent* jest kompromisem pomiędzy *batch gradient descent* a SGD: aktualizacja parametrów $\\mathbf{w}^{(\\tau)}$ odbywa się na podstawie gradientu funkcji straty $L(\\mathbf{w})$ obliczonego na podstawie *mini-batcha* próbek - podzbioru większego niż jedna próbka, ale mniejszego (zwykle znacznie) niż cały zbiór. \n",
    "\n",
    "Niech $B$ będzie liczbą próbek w *mini-batchu*. Jest to, podobnie jak $\\eta$, hiperparametr algorytmu. Formalnie $B$ jest dowolną liczbą między 1 a $N$, w praktyce jest zazwyczaj ustalane jako jakaś potęga 2. Możemy teraz dokonać uogólnienia wzoru z paragrafu o SGD:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "  L(\\mathbf{w}) &= \\frac{1}{N} \\sum_{n=1}^N L_n(\\mathbf{w}) \n",
    "  = \\frac{B}{N} \\sum_{k=1}^{N/B} \\frac{1}{B} \\sum_{j=1}^B L_{(k-1)B + j}(\\mathbf{w})\\\\\n",
    "  &= \\frac{B}{N} \\sum_{k=1}^{N/B} L_{(k-1)B + 1, (k-1)B + 2, \\ldots, kB}(\\mathbf{w}),\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $L_{(k-1)B + 1, (k-1)B + 2, \\ldots, kB}(\\mathbf{w})$ to strata dla próbek z *mini-batcha* o numerach od $(k-1)B + 1$ do $kB$. W każdym kroku aktualizujemy parametry $\\mathbf{w}^{(\\tau)}$ wykorzystując gradient obliczony na batchu $B$ próbek.\n",
    "\n",
    "Matematycznie:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "  \\mathbf{w}^{(0)} &= \\text{losowo ustalona początkowa wartość parametrów modelu} \\\\\n",
    "  \\mathbf{w}^{(\\tau)} &= \\mathbf{w}^{(\\tau - 1)} - \\eta \\nabla_{\\mathbf{w}} L_{n_1, n_2, \\ldots, n_B}(\\mathbf{w}^{(\\tau - 1)}),\\quad \\tau = 1, 2, \\ldots\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $n_1, n_2, \\ldots, n_B$ to numery próbek w *mini-batchu* zależne od kroku $\\tau$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mini-batch gradient descent* w pseudokodzie:\n",
    "\n",
    "> **Input**:\n",
    ">   * zbiór danych $\\mathcal{D} = \\{(\\mathbf{x}_n, y_n)\\}_{n=1}^N$,\n",
    ">   * funkcja straty $L_{n:n+B}(\\mathbf{w})$ obliczana na podstawie próbek $n:n+B$,\n",
    ">   * współczynnik uczenia $\\eta>0$,\n",
    ">   * rozmiar *mini-batcha* $B$,\n",
    ">   * losowo inicjalizowana początkowa wartość parametrów modelu $\\mathbf{w}$.\n",
    ">\n",
    "> **Output**:\n",
    ">   * parametry modelu $\\mathbf{w}$ po zakończeniu treningu.\n",
    ">\n",
    "> **Algorytm**:\n",
    "> 1. $n \\gets 1$.\n",
    "> 2. Powtarzaj:\n",
    ">    * $\\mathbf{w} \\gets \\mathbf{w} - \\eta \\nabla_{\\mathbf{w}} L_{n:n+B}(\\mathbf{w})$\n",
    ">    * $n \\gets n + B$\n",
    ">    * jeśli $n > N$, to:\n",
    ">      * wymieszaj dane $\\mathcal{D}$,\n",
    ">      * $n \\gets 1$.\n",
    "> 3. aż do osiągnięcia zbieżności.\n",
    "> 4. Zwróć $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym algorytmie **iteracja** to przetworzenie *mini-batcha* $B$ próbek, a **epoka** to, tak jak poprzednio, pełne przejście przez cały zbiór danych, czyli $N/B$ iteracji. \n",
    "\n",
    "Wyżej założyliśmy dla uproszczenia, że $N$ jest podzielne przez $B$. Jeśli tak nie jest, to w ostatniej iteracji po prostu przetwarzamy wszystkie pozostałe próbki, które nie zmieściły się w pełnych *mini-batchach*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensory i różniczkowanie automatyczne w PyTorch\n",
    "\n",
    "**Tensor** w PyTorch to wielowymiarowa tablica wartości numerycznych, podobna do tablic NumPy, ale z dodatkowymi możliwościami:\n",
    "\n",
    "- **Obsługa GPU**: Tensory mogą być przetwarzane na GPU.\n",
    "- **Różniczkowanie automatyczne**: PyTorch automatycznie oblicza gradienty dla operacji na tensorach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "X1 = np.random.rand(500, 2)\n",
    "X2 = (np.random.rand(500, 2) + .7)\n",
    "X = np.concatenate((X1, X2), axis=0)\n",
    "y = np.concatenate((np.zeros(500), np.ones(500)), axis=0)\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=10, cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglog = LogisticRegression()\n",
    "reglog.fit(X, y)\n",
    "y_pred = reglog.predict(X)\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zamiana numpy array na tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).view(-1, 2)\n",
    "X_tensor = torch.cat((torch.ones(X_tensor.shape[0], 1), X_tensor), dim=1)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Przygotowanie loaderów danych\n",
    "train_dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Definiowanie modelu\n",
    "def sigmoid(x, w):\n",
    "    return 1 / (1 + torch.exp(-(w[0] + w[1] * x[:, 1] + w[2] * x[:, 2])))\n",
    "\n",
    "# Definiowanie funkcji straty\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    y_pred = torch.clamp(y_pred, 1e-7, 1 - 1e-7)  # zapobieganie log(0)\n",
    "    return -torch.mean(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "\n",
    "# Inicjalizacja parametrów\n",
    "w = torch.tensor(np.random.rand(3), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "eta = .1 # learning rate\n",
    "\n",
    "# Trenowanie modelu metodą mini-batch gradient descent\n",
    "for epoch in range(10):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        y_pred = sigmoid(X_batch, w)\n",
    "        loss = binary_cross_entropy(y_batch, y_pred)\n",
    "        loss.backward() # obliczanie gradientów\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # aktualizacja wartości parametrów\n",
    "            w.data = w.data - eta * w.grad\n",
    "            # zerowanie gradientów\n",
    "            w.grad.zero_()\n",
    "            \n",
    "    print(f\"Epoch {epoch + 1}/{10}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sigmoid(X_tensor, w)\n",
    "y_pred = y_pred > 0.5\n",
    "confusion_matrix(y, y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Zamiana numpy array na tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).view(-1, 2)\n",
    "X_tensor = torch.cat((torch.ones(X_tensor.shape[0], 1), X_tensor), dim=1)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Przygotowanie loaderów danych\n",
    "train_dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Definiowanie modelu przy użyciu torch.nn\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.sigmoid(out)  \n",
    "        return out\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = LogisticRegression(input_dim=3)\n",
    "\n",
    "# Definiowanie funkcji straty i optymalizatora\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent\n",
    "\n",
    "# Trenowanie modelu\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass i optymalizacja\n",
    "        optimizer.zero_grad()  # zerowanie gradientów\n",
    "        loss.backward()        # obliczanie gradientów\n",
    "        optimizer.step()       # aktualizacja parametrów\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_tensor)\n",
    "y_pred = y_pred > 0.5\n",
    "confusion_matrix(y, y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, y_pred.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
